ðŸ“‚ Loading trajectories from /Users/irawadee.t/Desktop/classes/ptom-bench/cs329a/business_vacation_traj.jsonl...
âœ… Loaded 2000 trajectories

ðŸ”„ Converting trajectories to chatml format...
âœ… Generated 8186 training examples

ðŸ“Š Split:
  â€¢ Training: 7367 examples
  â€¢ Validation: 819 examples

âœ… Training data saved to: /Users/irawadee.t/Desktop/classes/ptom-bench/cs329a/finetuning/data/training_data.jsonl
âœ… Validation data saved to: /Users/irawadee.t/Desktop/classes/ptom-bench/cs329a/finetuning/data/validation_data.jsonl

ðŸ“Š Statistics:

By strategy type:
  â€¢ alternative_success: 1879 examples (1879 successful, 100.0%)
  â€¢ failed: 1137 examples (3 successful, 0.3%)
  â€¢ information_efficiency: 1829 examples (1765 successful, 96.5%)
  â€¢ optimal: 1293 examples (1293 successful, 100.0%)
  â€¢ recovery: 2048 examples (2043 successful, 99.8%)

======================================================================
âœ… Data preparation complete!
======================================================================

Next step:
  python finetune_llama.py --train-data /Users/irawadee.t/Desktop/classes/ptom-bench/cs329a/finetuning/data/training_data.jsonl
